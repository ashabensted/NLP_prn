{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5d4ccc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PRAW in c:\\users\\asha\\anaconda3\\lib\\site-packages (7.7.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in c:\\users\\asha\\anaconda3\\lib\\site-packages (from PRAW) (2.4.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\asha\\anaconda3\\lib\\site-packages (from PRAW) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\asha\\anaconda3\\lib\\site-packages (from PRAW) (0.58.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\asha\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.1->PRAW) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\asha\\anaconda3\\lib\\site-packages (from websocket-client>=0.54.0->PRAW) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asha\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->PRAW) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asha\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->PRAW) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asha\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->PRAW) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asha\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->PRAW) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk import stem\n",
    "stemmer = stem.PorterStemmer()\n",
    "from nltk import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words('english'))\n",
    "import string\n",
    "punct = list(string.punctuation)\n",
    "from collections import Counter\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install PRAW\n",
    "import numpy as np\n",
    "import praw\n",
    "import datetime\n",
    "\n",
    "reddit = praw.Reddit(user_agent='VAD',\n",
    "                     client_id='ZjY6Q02zjaGNUmfk5b282Q', client_secret=\"sgdNZo6bRPSeCaHAJACK5mNIUxCTgA\",\n",
    "                     username='liflafleof', password='surrenderx3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89fbe628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(submission_id): ## submission_id can be URL or submission ID\n",
    "    try:\n",
    "        submission = reddit.submission(url = submission_id)\n",
    "    except:\n",
    "        submission = reddit.submission(submission_id)\n",
    "    title = submission.title\n",
    "    submission.comments.replace_more() ## loads new page if cooments are multipage\n",
    "    text = [i.body for i in submission.comments]\n",
    "    score = [i.score for i in submission.comments]\n",
    "    user = [i.author for i in submission.comments]\n",
    "    date = [datetime.datetime.fromtimestamp(i.created) for i in submission.comments]\n",
    "    df = pd.DataFrame()\n",
    "    df['text'] = text\n",
    "    df['datetime'] = date\n",
    "    df['score'] = score\n",
    "    df['subreddit'] = submission.subreddit\n",
    "    df['redditor'] = user\n",
    "    df['type'] = 'comment'\n",
    "    df['title'] = title\n",
    "    df = df.sort_values('score', ascending = False).reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searched reddit for 'porn affect', 'porn effect', 'porn ethics', 'porn opinion', 'porn influence',\n",
    "#'porn industry','porn discussion' 'porn thoughts', 'porn sexuality', 'porn positive', 'pro porn', 'anti porn', 'porn feelings', and 'porn society'.\n",
    "# From these search results, I selected relevant posts that invited discussion and reflection on pornography from a range of subreddits dedicated to a variety of topics, favouring those with the most comments and only including posts with <100 comments if their question was explicitly relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#links: 'https://www.reddit.com/r/changemyview/comments/1b2cwhj/cmv_porn_should_not_be_so_normalised/' 1.3k com\n",
    "#'https://www.reddit.com/r/TwoXChromosomes/comments/1b4lyze/these_anti_porn_posts_are_becoming_very_moms_for/' #2.5k com\n",
    "#'https://www.reddit.com/r/science/comments/o58b2r/people_who_support_a_ban_on_pornography_tend_to/' #3.2k com\n",
    "#https://www.reddit.com/r/Marriage/comments/13jbcdw/this_subreddits_opinions_on_porn_doesnt_matter/ #451 commennts\n",
    "#https://www.reddit.com/r/dating/comments/rjxcp7/when_youre_in_a_committed_relationship_what_is/ #568 com\n",
    "#https://www.reddit.com/r/TrueUnpopularOpinion/comments/16htdo9/pornography_is_bad_for_you/ #696 com\n",
    "#https://www.reddit.com/r/datingoverthirty/comments/14fh4vl/thoughts_on_porn/ #397 com\n",
    "#https://www.reddit.com/r/AskReddit/comments/18fyqze/what_is_the_worst_porn_you_have_ever_seen/ #2.1k com\n",
    "#https://www.reddit.com/r/AskReddit/comments/134qwa/have_you_seen_this_ted_talk_about_internet_porn_i/ #943 com\n",
    "#https://www.reddit.com/r/AskReddit/comments/dl8pgo/people_who_pay_for_porn_why_do_pay_for_porn_what/ #474 com\n",
    "#https://www.reddit.com/r/AskReddit/comments/et5yc/honestly_who_doesnt_watch_porn/ #887 com\n",
    "#https://www.reddit.com/r/AskReddit/comments/1efk7s/what_aspects_about_sex_has_porn_totally_ruined/ #396 com \n",
    "#https://www.reddit.com/r/AskReddit/comments/vaasm/women_of_reddit_how_do_you_feel_about_your_man/ #471 com\n",
    "#https://www.reddit.com/r/AskReddit/comments/9lwt8/do_you_think_porn_harms_your_ability_to_be/ #318 com\n",
    "#https://www.reddit.com/r/technology/comments/pba73k/onlyfans_drops_planned_porn_ban_will_continue_to/ #4.2k com\n",
    "#https://www.reddit.com/r/TheGirlSurvivalGuide/comments/gl8ifn/im_really_not_cool_with_porn_anymore_and_i_feel/ #181 com\n",
    "#https://www.reddit.com/r/unpopularopinion/comments/cdtjun/porn_is_the_biggest_cancer_to_society_today/ #2.2k com\n",
    "#https://www.reddit.com/r/nottheonion/comments/4kouvz/utah_lawmaker_wants_porn_filtered_from_internet/ #2.5k com\n",
    "#https://www.reddit.com/r/theworldnews/comments/1368ofe/antiporn_lobbyists_pressure_reddit_to_shut_down/ #2.1k com\n",
    "#https://www.reddit.com/r/unpopularopinion/comments/l6okyk/i_dont_want_to_be_in_a_relationship_with_someone/ #6.8k com\n",
    "#https://www.reddit.com/r/AskMen/comments/wona9w/men_whats_your_honest_opinion_on_pornography/ #880 com\n",
    "#https://www.reddit.com/r/TwoXChromosomes/comments/ua4hdy/teen_should_be_banned_as_a_title_or_tag_for_porn/ #1k com\n",
    "#https://www.reddit.com/r/unpopularopinion/comments/9iih3b/porn_has_ruined_an_entire_generations_sexuality/ #1.5k com\n",
    "#https://www.reddit.com/r/SubredditDrama/comments/og8blw/runpopularopinion_turns_into_a_chaotic_warzone/ #1.3k com\n",
    "#https://www.reddit.com/r/unpopularopinion/comments/ofj35h/legal_age_for_porn_stars_should_be_21_not_18/?utm_source=share&utm_medium=web2x&context=3 #7.5k com\n",
    "#https://www.reddit.com/r/sex/comments/3y1sb2/discussion_a_warning_if_you_want_to_get_into_porn/?xpromo_edp=enabled #462 com\n",
    "#https://www.reddit.com/r/sex/comments/qwy190/im_sick_of_having_incest_porn_shoved_in_my_face/?xpromo_edp=enabled #269 com\n",
    "#https://www.reddit.com/r/askgaybros/comments/189xoag/what_are_your_honest_thoughts_on_porn_industry/ #125 com\n",
    "#https://www.reddit.com/r/sex/comments/nb9bsc/at_25_im_just_realising_the_influence_porn_has_on/?xpromo_edp=enabled #515 com\n",
    "#https://www.reddit.com/r/AskReddit/comments/2kzo9k/what_is_a_lie_from_porn_that_you_fell_for/ #2k com\n",
    "#https://www.reddit.com/r/philosophy/comments/it083/noam_chomsky_discusses_his_views_on_pornography/ #263 com\n",
    "#https://www.reddit.com/r/Equality/comments/81l43/ask_equality_what_is_your_opinion_on_pornography/ #109 com\n",
    "#https://www.reddit.com/r/women/comments/cezwpk/women_of_reddit_whats_your_opinion_on_porn/ #68 com\n",
    "#https://www.reddit.com/r/philosophy/comments/171xtq/is_pornography_unethical/ #99 com \n",
    "#https://www.reddit.com/r/TwoXChromosomes/comments/xml8as/the_ethics_of_men_watching_porn_wouldnt_bother_me/ #616 com \n",
    "#https://www.reddit.com/r/MensLib/comments/jii7wq/pay_for_your_porn/ #661 com\n",
    "#https://www.reddit.com/r/sex/comments/1b2x8r2/is_there_such_thing_as_ethical_porn/ #59 com\n",
    "#https://www.reddit.com/r/changemyview/comments/s7r2vr/cmv_hentai_is_ethical_porn/ #346 com\n",
    "#https://www.reddit.com/r/sex/comments/5b45tk/porn_how_can_i_tell_if_a_porn_studio_is_ethically/ #175 com\n",
    "#https://www.reddit.com/r/DebateReligion/comments/53gxi5/is_porn_ethical/ #143 com\n",
    "#https://www.reddit.com/r/Feminism/comments/h7fh4t/how_do_you_feel_about_porn_ethically_speaking/ #67 com\n",
    "#https://www.reddit.com/r/ukpolitics/comments/bf0le1/age_verification_wont_block_porn_but_it_will/ #88 com\n",
    "# https://www.reddit.com/r/antipornography/comments/10fe92e/ethical_porn/ #56 com\n",
    "# https://www.reddit.com/r/antipornography/comments/see151/whats_your_opinion_on_ethical_porn/ #85 com\n",
    "# https://www.reddit.com/r/Advice/comments/i5ifvf/how_can_i_watch_porn_ethically/ #29 com\n",
    "#https://www.reddit.com/r/changemyview/comments/185skh3/cmv_i_think_its_insecure_for_people_to_try_to/ #924 com\n",
    "#https://www.reddit.com/r/askphilosophy/comments/dxhlua/porn_and_ethics/ #25 com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e613ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://www.reddit.com/r/changemyview/comments/1b2cwhj/cmv_porn_should_not_be_so_normalised/', \n",
    "         'https://www.reddit.com/r/TwoXChromosomes/comments/1b4lyze/these_anti_porn_posts_are_becoming_very_moms_for/' ,\n",
    "         'https://www.reddit.com/r/science/comments/o58b2r/people_who_support_a_ban_on_pornography_tend_to/' , \n",
    "         'https://www.reddit.com/r/Marriage/comments/13jbcdw/this_subreddits_opinions_on_porn_doesnt_matter/',\n",
    "         'https://www.reddit.com/r/dating/comments/rjxcp7/when_youre_in_a_committed_relationship_what_is/' , \n",
    "         'https://www.reddit.com/r/TrueUnpopularOpinion/comments/16htdo9/pornography_is_bad_for_you/' ,\n",
    "         'https://www.reddit.com/r/datingoverthirty/comments/14fh4vl/thoughts_on_porn/' ,\n",
    "         'https://www.reddit.com/r/AskReddit/comments/18fyqze/what_is_the_worst_porn_you_have_ever_seen/' ,\n",
    "         'https://www.reddit.com/r/AskReddit/comments/134qwa/have_you_seen_this_ted_talk_about_internet_porn_i/' , \n",
    "         'https://www.reddit.com/r/AskReddit/comments/dl8pgo/people_who_pay_for_porn_why_do_pay_for_porn_what/' ,\n",
    "         'https://www.reddit.com/r/AskReddit/comments/et5yc/honestly_who_doesnt_watch_porn/' ,\n",
    "         'https://www.reddit.com/r/AskReddit/comments/1efk7s/what_aspects_about_sex_has_porn_totally_ruined/' ,\n",
    "         'https://www.reddit.com/r/AskReddit/comments/vaasm/women_of_reddit_how_do_you_feel_about_your_man/' ,\n",
    "         'https://www.reddit.com/r/AskReddit/comments/9lwt8/do_you_think_porn_harms_your_ability_to_be/' ,\n",
    "         'https://www.reddit.com/r/technology/comments/pba73k/onlyfans_drops_planned_porn_ban_will_continue_to/' ,\n",
    "         'https://www.reddit.com/r/TheGirlSurvivalGuide/comments/gl8ifn/im_really_not_cool_with_porn_anymore_and_i_feel/' ,\n",
    "         'https://www.reddit.com/r/unpopularopinion/comments/cdtjun/porn_is_the_biggest_cancer_to_society_today/' ,\n",
    "         'https://www.reddit.com/r/nottheonion/comments/4kouvz/utah_lawmaker_wants_porn_filtered_from_internet/' ,\n",
    "         'https://www.reddit.com/r/theworldnews/comments/1368ofe/antiporn_lobbyists_pressure_reddit_to_shut_down/' ,\n",
    "         'https://www.reddit.com/r/unpopularopinion/comments/l6okyk/i_dont_want_to_be_in_a_relationship_with_someone/' ,\n",
    "         'https://www.reddit.com/r/AskMen/comments/wona9w/men_whats_your_honest_opinion_on_pornography/' ,\n",
    "         'https://www.reddit.com/r/TwoXChromosomes/comments/ua4hdy/teen_should_be_banned_as_a_title_or_tag_for_porn/' ,\n",
    "         'https://www.reddit.com/r/unpopularopinion/comments/9iih3b/porn_has_ruined_an_entire_generations_sexuality/' ,\n",
    "         'https://www.reddit.com/r/SubredditDrama/comments/og8blw/runpopularopinion_turns_into_a_chaotic_warzone/' ,\n",
    "         'https://www.reddit.com/r/unpopularopinion/comments/ofj35h/legal_age_for_porn_stars_should_be_21_not_18/?utm_source=share&utm_medium=web2x&context=3' ,\n",
    "         'https://www.reddit.com/r/sex/comments/3y1sb2/discussion_a_warning_if_you_want_to_get_into_porn/?xpromo_edp=enabled' ,\n",
    "         'https://www.reddit.com/r/sex/comments/qwy190/im_sick_of_having_incest_porn_shoved_in_my_face/?xpromo_edp=enabled' ,\n",
    "         'https://www.reddit.com/r/askgaybros/comments/189xoag/what_are_your_honest_thoughts_on_porn_industry/' ,\n",
    "         'https://www.reddit.com/r/sex/comments/nb9bsc/at_25_im_just_realising_the_influence_porn_has_on/?xpromo_edp=enabled' ,\n",
    "         'https://www.reddit.com/r/AskReddit/comments/2kzo9k/what_is_a_lie_from_porn_that_you_fell_for/' ,\n",
    "         'https://www.reddit.com/r/philosophy/comments/it083/noam_chomsky_discusses_his_views_on_pornography/' ,\n",
    "         'https://www.reddit.com/r/Equality/comments/81l43/ask_equality_what_is_your_opinion_on_pornography/' ,\n",
    "         'https://www.reddit.com/r/women/comments/cezwpk/women_of_reddit_whats_your_opinion_on_porn/' ,\n",
    "         'https://www.reddit.com/r/philosophy/comments/171xtq/is_pornography_unethical/',\n",
    "         'https://www.reddit.com/r/TwoXChromosomes/comments/xml8as/the_ethics_of_men_watching_porn_wouldnt_bother_me/' ,\n",
    "         'https://www.reddit.com/r/MensLib/comments/jii7wq/pay_for_your_porn/',\n",
    "         'https://www.reddit.com/r/sex/comments/1b2x8r2/is_there_such_thing_as_ethical_porn/',\n",
    "         'https://www.reddit.com/r/changemyview/comments/s7r2vr/cmv_hentai_is_ethical_porn/',\n",
    "         'https://www.reddit.com/r/sex/comments/5b45tk/porn_how_can_i_tell_if_a_porn_studio_is_ethically/',\n",
    "         'https://www.reddit.com/r/DebateReligion/comments/53gxi5/is_porn_ethical/' ,\n",
    "         'https://www.reddit.com/r/Feminism/comments/h7fh4t/how_do_you_feel_about_porn_ethically_speaking/',\n",
    "         'https://www.reddit.com/r/ukpolitics/comments/bf0le1/age_verification_wont_block_porn_but_it_will/' ,\n",
    "         'https://www.reddit.com/r/antipornography/comments/10fe92e/ethical_porn/',\n",
    "         'https://www.reddit.com/r/antipornography/comments/see151/whats_your_opinion_on_ethical_porn/',\n",
    "         'https://www.reddit.com/r/Advice/comments/i5ifvf/how_can_i_watch_porn_ethically/',\n",
    "         'https://www.reddit.com/r/changemyview/comments/185skh3/cmv_i_think_its_insecure_for_people_to_try_to/' ,\n",
    "         'https://www.reddit.com/r/askphilosophy/comments/dxhlua/porn_and_ethics/' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0adfe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "dfs = []\n",
    "for link in links:\n",
    "    while True:\n",
    "        try:\n",
    "            df = submission(link)\n",
    "            dfs.append(df)\n",
    "            break  # Break the loop if the request is successful\n",
    "        except praw.exceptions.RedditAPIException as e:\n",
    "            if e.error_type == 'RATELIMIT':\n",
    "                # If the error is due to rate limiting, sleep for a while and retry\n",
    "                time.sleep(60)  # Sleep for 30 seconds before retrying\n",
    "            else:\n",
    "                # If it's another type of error, raise it again\n",
    "                raise e\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "final_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07412be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>redditor</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No, those things happen because porn, and talk...</td>\n",
       "      <td>2024-02-28 18:22:32</td>\n",
       "      <td>572</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>PandaMime_421</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Porn may contribute, but it is not the only ca...</td>\n",
       "      <td>2024-02-28 19:50:42</td>\n",
       "      <td>363</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>ojisan-X</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think this depends on what you mean by \"norm...</td>\n",
       "      <td>2024-02-28 18:24:19</td>\n",
       "      <td>274</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>AcephalicDude</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’d like to flip this argument and say that it...</td>\n",
       "      <td>2024-02-29 04:35:42</td>\n",
       "      <td>245</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>Glorfindale</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How is it 'normalized'? You were actively brea...</td>\n",
       "      <td>2024-02-28 18:13:17</td>\n",
       "      <td>71</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>Hellioning</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13758</th>\n",
       "      <td>What we define as \"corrupting the body and min...</td>\n",
       "      <td>2019-11-17 09:43:42</td>\n",
       "      <td>2</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>Aestreal</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13759</th>\n",
       "      <td>[removed]</td>\n",
       "      <td>2019-11-17 05:03:25</td>\n",
       "      <td>1</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>None</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13760</th>\n",
       "      <td>[removed]</td>\n",
       "      <td>2019-11-17 05:47:35</td>\n",
       "      <td>1</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>None</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13761</th>\n",
       "      <td>[removed]</td>\n",
       "      <td>2019-11-17 06:02:04</td>\n",
       "      <td>1</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>None</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13762</th>\n",
       "      <td>[removed]</td>\n",
       "      <td>2019-11-17 15:17:20</td>\n",
       "      <td>1</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>None</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13763 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text            datetime  \\\n",
       "0      No, those things happen because porn, and talk... 2024-02-28 18:22:32   \n",
       "1      Porn may contribute, but it is not the only ca... 2024-02-28 19:50:42   \n",
       "2      I think this depends on what you mean by \"norm... 2024-02-28 18:24:19   \n",
       "3      I’d like to flip this argument and say that it... 2024-02-29 04:35:42   \n",
       "4      How is it 'normalized'? You were actively brea... 2024-02-28 18:13:17   \n",
       "...                                                  ...                 ...   \n",
       "13758  What we define as \"corrupting the body and min... 2019-11-17 09:43:42   \n",
       "13759                                          [removed] 2019-11-17 05:03:25   \n",
       "13760                                          [removed] 2019-11-17 05:47:35   \n",
       "13761                                          [removed] 2019-11-17 06:02:04   \n",
       "13762                                          [removed] 2019-11-17 15:17:20   \n",
       "\n",
       "       score      subreddit       redditor     type  \\\n",
       "0        572   changemyview  PandaMime_421  comment   \n",
       "1        363   changemyview       ojisan-X  comment   \n",
       "2        274   changemyview  AcephalicDude  comment   \n",
       "3        245   changemyview    Glorfindale  comment   \n",
       "4         71   changemyview     Hellioning  comment   \n",
       "...      ...            ...            ...      ...   \n",
       "13758      2  askphilosophy       Aestreal  comment   \n",
       "13759      1  askphilosophy           None  comment   \n",
       "13760      1  askphilosophy           None  comment   \n",
       "13761      1  askphilosophy           None  comment   \n",
       "13762      1  askphilosophy           None  comment   \n",
       "\n",
       "                                       title  \n",
       "0      Cmv: Porn should not be so normalised  \n",
       "1      Cmv: Porn should not be so normalised  \n",
       "2      Cmv: Porn should not be so normalised  \n",
       "3      Cmv: Porn should not be so normalised  \n",
       "4      Cmv: Porn should not be so normalised  \n",
       "...                                      ...  \n",
       "13758                        Porn and ethics  \n",
       "13759                        Porn and ethics  \n",
       "13760                        Porn and ethics  \n",
       "13761                        Porn and ethics  \n",
       "13762                        Porn and ethics  \n",
       "\n",
       "[13763 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90961595",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner_final_df = final_df[final_df.text != '[removed]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25bab761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>redditor</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No, those things happen because porn, and talk...</td>\n",
       "      <td>2024-02-28 18:22:32</td>\n",
       "      <td>572</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>PandaMime_421</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Porn may contribute, but it is not the only ca...</td>\n",
       "      <td>2024-02-28 19:50:42</td>\n",
       "      <td>363</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>ojisan-X</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think this depends on what you mean by \"norm...</td>\n",
       "      <td>2024-02-28 18:24:19</td>\n",
       "      <td>274</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>AcephalicDude</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’d like to flip this argument and say that it...</td>\n",
       "      <td>2024-02-29 04:35:42</td>\n",
       "      <td>245</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>Glorfindale</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How is it 'normalized'? You were actively brea...</td>\n",
       "      <td>2024-02-28 18:13:17</td>\n",
       "      <td>71</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>Hellioning</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13754</th>\n",
       "      <td>The question of whether or not pronography is ...</td>\n",
       "      <td>2019-11-17 06:33:48</td>\n",
       "      <td>20</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>Beor_The_Old</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13755</th>\n",
       "      <td>The obvious. Degrading either sex to a mere ob...</td>\n",
       "      <td>2019-11-17 04:13:22</td>\n",
       "      <td>18</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>Philosophical_bent</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13756</th>\n",
       "      <td>I would recommend reading *Are Women Human?* b...</td>\n",
       "      <td>2019-11-17 17:18:05</td>\n",
       "      <td>3</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>ObsceneBird</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13757</th>\n",
       "      <td>See Langton's \"Speech Acts and Unspeakable Act...</td>\n",
       "      <td>2019-11-17 16:28:12</td>\n",
       "      <td>3</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>cypro-</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13758</th>\n",
       "      <td>What we define as \"corrupting the body and min...</td>\n",
       "      <td>2019-11-17 09:43:42</td>\n",
       "      <td>2</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>Aestreal</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13593 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text            datetime  \\\n",
       "0      No, those things happen because porn, and talk... 2024-02-28 18:22:32   \n",
       "1      Porn may contribute, but it is not the only ca... 2024-02-28 19:50:42   \n",
       "2      I think this depends on what you mean by \"norm... 2024-02-28 18:24:19   \n",
       "3      I’d like to flip this argument and say that it... 2024-02-29 04:35:42   \n",
       "4      How is it 'normalized'? You were actively brea... 2024-02-28 18:13:17   \n",
       "...                                                  ...                 ...   \n",
       "13754  The question of whether or not pronography is ... 2019-11-17 06:33:48   \n",
       "13755  The obvious. Degrading either sex to a mere ob... 2019-11-17 04:13:22   \n",
       "13756  I would recommend reading *Are Women Human?* b... 2019-11-17 17:18:05   \n",
       "13757  See Langton's \"Speech Acts and Unspeakable Act... 2019-11-17 16:28:12   \n",
       "13758  What we define as \"corrupting the body and min... 2019-11-17 09:43:42   \n",
       "\n",
       "       score      subreddit            redditor     type  \\\n",
       "0        572   changemyview       PandaMime_421  comment   \n",
       "1        363   changemyview            ojisan-X  comment   \n",
       "2        274   changemyview       AcephalicDude  comment   \n",
       "3        245   changemyview         Glorfindale  comment   \n",
       "4         71   changemyview          Hellioning  comment   \n",
       "...      ...            ...                 ...      ...   \n",
       "13754     20  askphilosophy        Beor_The_Old  comment   \n",
       "13755     18  askphilosophy  Philosophical_bent  comment   \n",
       "13756      3  askphilosophy         ObsceneBird  comment   \n",
       "13757      3  askphilosophy              cypro-  comment   \n",
       "13758      2  askphilosophy            Aestreal  comment   \n",
       "\n",
       "                                       title  \n",
       "0      Cmv: Porn should not be so normalised  \n",
       "1      Cmv: Porn should not be so normalised  \n",
       "2      Cmv: Porn should not be so normalised  \n",
       "3      Cmv: Porn should not be so normalised  \n",
       "4      Cmv: Porn should not be so normalised  \n",
       "...                                      ...  \n",
       "13754                        Porn and ethics  \n",
       "13755                        Porn and ethics  \n",
       "13756                        Porn and ethics  \n",
       "13757                        Porn and ethics  \n",
       "13758                        Porn and ethics  \n",
       "\n",
       "[13593 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7cd8b7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\asha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "def lemma(text) :\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    lemmas = [lemmatizer.lemmatize(i.lower()) for i in tokens]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1068f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [lemma(i) for i in cleaner_final_df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2c12b770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['thing',\n",
       "  'happen',\n",
       "  'porn',\n",
       "  'talking',\n",
       "  \"n't\",\n",
       "  'normalized',\n",
       "  'many',\n",
       "  'people',\n",
       "  'porn',\n",
       "  'sea',\n",
       "  'chaos',\n",
       "  'framework',\n",
       "  'navigate',\n",
       "  'hear',\n",
       "  'story',\n",
       "  'story',\n",
       "  'people',\n",
       "  'seem',\n",
       "  'completely',\n",
       "  'unable',\n",
       "  'differentiate',\n",
       "  'fantasy',\n",
       "  'porn',\n",
       "  'reality',\n",
       "  'healthy',\n",
       "  'sexuality',\n",
       "  'relationship',\n",
       "  'worst',\n",
       "  'part',\n",
       "  'porn',\n",
       "  'industry',\n",
       "  'largely',\n",
       "  'made',\n",
       "  'possible',\n",
       "  'fact',\n",
       "  'still',\n",
       "  'taboo',\n",
       "  'society',\n",
       "  'lot',\n",
       "  'issue',\n",
       "  'ignoring',\n",
       "  \"n't\",\n",
       "  'going',\n",
       "  'fix'],\n",
       " ['porn',\n",
       "  'may',\n",
       "  'contribute',\n",
       "  'cause',\n",
       "  'elephant',\n",
       "  'room',\n",
       "  'objectifying',\n",
       "  'woman',\n",
       "  'mostly',\n",
       "  'come',\n",
       "  'parental',\n",
       "  'peer',\n",
       "  'influence',\n",
       "  'well',\n",
       "  'medium',\n",
       "  'people',\n",
       "  'consume',\n",
       "  'porn',\n",
       "  'well',\n",
       "  'porn',\n",
       "  'one',\n",
       "  'influence',\n",
       "  'getting',\n",
       "  'rid',\n",
       "  'really',\n",
       "  'solution',\n",
       "  \"'s\",\n",
       "  'attempt',\n",
       "  'put',\n",
       "  'lid',\n",
       "  'something',\n",
       "  \"n't\",\n",
       "  'want',\n",
       "  'see',\n",
       "  'parent',\n",
       "  'need',\n",
       "  'educate',\n",
       "  'child',\n",
       "  'real',\n",
       "  \"'s\",\n",
       "  'foster',\n",
       "  'respect',\n",
       "  'people',\n",
       "  'influence',\n",
       "  'parent',\n",
       "  'blaming',\n",
       "  'crime',\n",
       "  'entertainment',\n",
       "  'old',\n",
       "  'argument',\n",
       "  '``',\n",
       "  'x',\n",
       "  'cause',\n",
       "  'everyone',\n",
       "  \"''\",\n",
       "  'answer',\n",
       "  'simply'],\n",
       " ['think',\n",
       "  'depends',\n",
       "  'mean',\n",
       "  '``',\n",
       "  'normalized',\n",
       "  \"''\",\n",
       "  \"'s\",\n",
       "  'definitely',\n",
       "  '``',\n",
       "  'normalized',\n",
       "  \"''\",\n",
       "  'sense',\n",
       "  'still',\n",
       "  'highly',\n",
       "  'controversial',\n",
       "  'still',\n",
       "  'consumed',\n",
       "  'completely',\n",
       "  'private',\n",
       "  '``',\n",
       "  'normalized',\n",
       "  \"''\",\n",
       "  'sense',\n",
       "  'basically',\n",
       "  'always',\n",
       "  'existed',\n",
       "  'one',\n",
       "  'form',\n",
       "  'another',\n",
       "  'throughout',\n",
       "  'human',\n",
       "  'history',\n",
       "  'seems',\n",
       "  'inevitable',\n",
       "  'human',\n",
       "  'being',\n",
       "  'create',\n",
       "  'erotic',\n",
       "  'imagery',\n",
       "  'literature',\n",
       "  'art',\n",
       "  'etc',\n",
       "  'broader',\n",
       "  'sense',\n",
       "  \"n't\",\n",
       "  'think',\n",
       "  \"'d\",\n",
       "  'able',\n",
       "  '``',\n",
       "  'de-normalize',\n",
       "  \"''\",\n",
       "  'porn',\n",
       "  'even',\n",
       "  'tried',\n",
       "  'opinion',\n",
       "  'focus',\n",
       "  'instead',\n",
       "  'making',\n",
       "  'better',\n",
       "  'porn',\n",
       "  'depicts',\n",
       "  'healthier',\n",
       "  'form',\n",
       "  'eroticism',\n",
       "  'sexuality',\n",
       "  'type',\n",
       "  'sex-positive',\n",
       "  'porn',\n",
       "  'already',\n",
       "  'exists',\n",
       "  \"n't\",\n",
       "  'enough',\n",
       "  'put',\n",
       "  'le',\n",
       "  'likely',\n",
       "  'curious',\n",
       "  '11',\n",
       "  'year-old',\n",
       "  'fuck',\n",
       "  'sense',\n",
       "  'sexuality',\n",
       "  'stumble',\n",
       "  'upon'],\n",
       " ['’',\n",
       "  'like',\n",
       "  'flip',\n",
       "  'argument',\n",
       "  'say',\n",
       "  '’',\n",
       "  'porn',\n",
       "  'normalized',\n",
       "  'objectification',\n",
       "  '’',\n",
       "  'culture',\n",
       "  'shaped',\n",
       "  'porn',\n",
       "  'sex',\n",
       "  'people',\n",
       "  'beautiful',\n",
       "  'tender',\n",
       "  'mutual',\n",
       "  'respect',\n",
       "  'sensuality',\n",
       "  'even',\n",
       "  'filmed',\n",
       "  'porn',\n",
       "  'representation',\n",
       "  'issue',\n",
       "  '’',\n",
       "  'already',\n",
       "  'society',\n",
       "  'visceral',\n",
       "  'form',\n",
       "  'society',\n",
       "  'influenced',\n",
       "  'porn',\n",
       "  'prior',\n",
       "  'porn',\n",
       "  'influencing',\n",
       "  'society'],\n",
       " [\"'normalized\", 'actively', 'breaking', 'rule', 'look', 'porn', '11']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d6a32706",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner_final_df = cleaner_final_df.assign(lemmas=lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0202f465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>redditor</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No, those things happen because porn, and talk...</td>\n",
       "      <td>2024-02-28 18:22:32</td>\n",
       "      <td>572</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>PandaMime_421</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "      <td>[thing, happen, porn, talking, n't, normalized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Porn may contribute, but it is not the only ca...</td>\n",
       "      <td>2024-02-28 19:50:42</td>\n",
       "      <td>363</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>ojisan-X</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "      <td>[porn, may, contribute, cause, elephant, room,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think this depends on what you mean by \"norm...</td>\n",
       "      <td>2024-02-28 18:24:19</td>\n",
       "      <td>274</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>AcephalicDude</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "      <td>[think, depends, mean, ``, normalized, '', 's,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’d like to flip this argument and say that it...</td>\n",
       "      <td>2024-02-29 04:35:42</td>\n",
       "      <td>245</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>Glorfindale</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "      <td>[’, like, flip, argument, say, ’, porn, normal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How is it 'normalized'? You were actively brea...</td>\n",
       "      <td>2024-02-28 18:13:17</td>\n",
       "      <td>71</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>Hellioning</td>\n",
       "      <td>comment</td>\n",
       "      <td>Cmv: Porn should not be so normalised</td>\n",
       "      <td>['normalized, actively, breaking, rule, look, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13754</th>\n",
       "      <td>The question of whether or not pronography is ...</td>\n",
       "      <td>2019-11-17 06:33:48</td>\n",
       "      <td>20</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>Beor_The_Old</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "      <td>[question, whether, pronography, corrupting, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13755</th>\n",
       "      <td>The obvious. Degrading either sex to a mere ob...</td>\n",
       "      <td>2019-11-17 04:13:22</td>\n",
       "      <td>18</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>Philosophical_bent</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "      <td>[obvious, degrading, either, sex, mere, object...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13756</th>\n",
       "      <td>I would recommend reading *Are Women Human?* b...</td>\n",
       "      <td>2019-11-17 17:18:05</td>\n",
       "      <td>3</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>ObsceneBird</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "      <td>[would, recommend, reading, woman, human, cath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13757</th>\n",
       "      <td>See Langton's \"Speech Acts and Unspeakable Act...</td>\n",
       "      <td>2019-11-17 16:28:12</td>\n",
       "      <td>3</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>cypro-</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "      <td>[see, langton, 's, ``, speech, act, unspeakabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13758</th>\n",
       "      <td>What we define as \"corrupting the body and min...</td>\n",
       "      <td>2019-11-17 09:43:42</td>\n",
       "      <td>2</td>\n",
       "      <td>askphilosophy</td>\n",
       "      <td>Aestreal</td>\n",
       "      <td>comment</td>\n",
       "      <td>Porn and ethics</td>\n",
       "      <td>[define, ``, corrupting, body, mind, '', prett...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13593 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text            datetime  \\\n",
       "0      No, those things happen because porn, and talk... 2024-02-28 18:22:32   \n",
       "1      Porn may contribute, but it is not the only ca... 2024-02-28 19:50:42   \n",
       "2      I think this depends on what you mean by \"norm... 2024-02-28 18:24:19   \n",
       "3      I’d like to flip this argument and say that it... 2024-02-29 04:35:42   \n",
       "4      How is it 'normalized'? You were actively brea... 2024-02-28 18:13:17   \n",
       "...                                                  ...                 ...   \n",
       "13754  The question of whether or not pronography is ... 2019-11-17 06:33:48   \n",
       "13755  The obvious. Degrading either sex to a mere ob... 2019-11-17 04:13:22   \n",
       "13756  I would recommend reading *Are Women Human?* b... 2019-11-17 17:18:05   \n",
       "13757  See Langton's \"Speech Acts and Unspeakable Act... 2019-11-17 16:28:12   \n",
       "13758  What we define as \"corrupting the body and min... 2019-11-17 09:43:42   \n",
       "\n",
       "       score      subreddit            redditor     type  \\\n",
       "0        572   changemyview       PandaMime_421  comment   \n",
       "1        363   changemyview            ojisan-X  comment   \n",
       "2        274   changemyview       AcephalicDude  comment   \n",
       "3        245   changemyview         Glorfindale  comment   \n",
       "4         71   changemyview          Hellioning  comment   \n",
       "...      ...            ...                 ...      ...   \n",
       "13754     20  askphilosophy        Beor_The_Old  comment   \n",
       "13755     18  askphilosophy  Philosophical_bent  comment   \n",
       "13756      3  askphilosophy         ObsceneBird  comment   \n",
       "13757      3  askphilosophy              cypro-  comment   \n",
       "13758      2  askphilosophy            Aestreal  comment   \n",
       "\n",
       "                                       title  \\\n",
       "0      Cmv: Porn should not be so normalised   \n",
       "1      Cmv: Porn should not be so normalised   \n",
       "2      Cmv: Porn should not be so normalised   \n",
       "3      Cmv: Porn should not be so normalised   \n",
       "4      Cmv: Porn should not be so normalised   \n",
       "...                                      ...   \n",
       "13754                        Porn and ethics   \n",
       "13755                        Porn and ethics   \n",
       "13756                        Porn and ethics   \n",
       "13757                        Porn and ethics   \n",
       "13758                        Porn and ethics   \n",
       "\n",
       "                                                  lemmas  \n",
       "0      [thing, happen, porn, talking, n't, normalized...  \n",
       "1      [porn, may, contribute, cause, elephant, room,...  \n",
       "2      [think, depends, mean, ``, normalized, '', 's,...  \n",
       "3      [’, like, flip, argument, say, ’, porn, normal...  \n",
       "4      ['normalized, actively, breaking, rule, look, ...  \n",
       "...                                                  ...  \n",
       "13754  [question, whether, pronography, corrupting, m...  \n",
       "13755  [obvious, degrading, either, sex, mere, object...  \n",
       "13756  [would, recommend, reading, woman, human, cath...  \n",
       "13757  [see, langton, 's, ``, speech, act, unspeakabl...  \n",
       "13758  [define, ``, corrupting, body, mind, '', prett...  \n",
       "\n",
       "[13593 rows x 8 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ca848c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import nltk\n",
      "nltk.download('punkt')\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "lemmatizer = WordNetLemmatizer()\n",
      "from nltk import stem\n",
      "stemmer = stem.PorterStemmer()\n",
      "from nltk import word_tokenize\n",
      "nltk.download('stopwords')\n",
      "from nltk.corpus import stopwords\n",
      "stops = set(stopwords.words('english'))\n",
      "import string\n",
      "punct = list(string.punctuation)\n",
      "from collections import Counter\n",
      "import requests\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "sns.set()\n",
      "import matplotlib.pyplot as plt\n",
      "!pip install PRAW\n",
      "import numpy as np\n",
      "import praw\n",
      "import datetime\n",
      "\n",
      "reddit = praw.Reddit(user_agent='VAD',\n",
      "                     client_id='ZjY6Q02zjaGNUmfk5b282Q', client_secret=\"sgdNZo6bRPSeCaHAJACK5mNIUxCTgA\",\n",
      "                     username='liflafleof', password='surrenderx3')\n",
      "def submission(submission_id): ## submission_id can be URL or submission ID\n",
      "    try:\n",
      "        submission = reddit.submission(url = submission_id)\n",
      "    except:\n",
      "        submission = reddit.submission(submission_id)\n",
      "    title = submission.title\n",
      "    submission.comments.replace_more() ## loads new page if cooments are multipage\n",
      "    text = [i.body for i in submission.comments]\n",
      "    score = [i.score for i in submission.comments]\n",
      "    user = [i.author for i in submission.comments]\n",
      "    date = [datetime.datetime.fromtimestamp(i.created) for i in submission.comments]\n",
      "    df = pd.DataFrame()\n",
      "    df['text'] = text\n",
      "    df['datetime'] = date\n",
      "    df['score'] = score\n",
      "    df['subreddit'] = submission.subreddit\n",
      "    df['redditor'] = user\n",
      "    df['type'] = 'comment'\n",
      "    df['title'] = title\n",
      "    df = df.sort_values('score', ascending = False).reset_index(drop = True)\n",
      "    return df\n",
      "links = ['https://www.reddit.com/r/changemyview/comments/1b2cwhj/cmv_porn_should_not_be_so_normalised/', \n",
      "         'https://www.reddit.com/r/TwoXChromosomes/comments/1b4lyze/these_anti_porn_posts_are_becoming_very_moms_for/' ,\n",
      "         'https://www.reddit.com/r/science/comments/o58b2r/people_who_support_a_ban_on_pornography_tend_to/' , \n",
      "         'https://www.reddit.com/r/Marriage/comments/13jbcdw/this_subreddits_opinions_on_porn_doesnt_matter/',\n",
      "         'https://www.reddit.com/r/dating/comments/rjxcp7/when_youre_in_a_committed_relationship_what_is/' , \n",
      "         'https://www.reddit.com/r/TrueUnpopularOpinion/comments/16htdo9/pornography_is_bad_for_you/' ,\n",
      "         'https://www.reddit.com/r/unpopularopinion/comments/l6okyk/i_dont_want_to_be_in_a_relationship_with_someone/' ,\n",
      "         'https://www.reddit.com/r/datingoverthirty/comments/14fh4vl/thoughts_on_porn/' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/18fyqze/what_is_the_worst_porn_you_have_ever_seen/' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/134qwa/have_you_seen_this_ted_talk_about_internet_porn_i/' , \n",
      "         'https://www.reddit.com/r/AskReddit/comments/dl8pgo/people_who_pay_for_porn_why_do_pay_for_porn_what/' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/et5yc/honestly_who_doesnt_watch_porn/' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/1efk7s/what_aspects_about_sex_has_porn_totally_ruined/' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/vaasm/women_of_reddit_how_do_you_feel_about_your_man/' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/9lwt8/do_you_think_porn_harms_your_ability_to_be/' ,\n",
      "         'https://www.reddit.com/r/technology/comments/pba73k/onlyfans_drops_planned_porn_ban_will_continue_to/' ,\n",
      "         'https://www.reddit.com/r/TheGirlSurvivalGuide/comments/gl8ifn/im_really_not_cool_with_porn_anymore_and_i_feel/' ,\n",
      "         'https://www.reddit.com/r/unpopularopinion/comments/cdtjun/porn_is_the_biggest_cancer_to_society_today/' ,\n",
      "         'https://www.reddit.com/r/nottheonion/comments/4kouvz/utah_lawmaker_wants_porn_filtered_from_internet/' ,\n",
      "         'https://www.reddit.com/r/theworldnews/comments/1368ofe/antiporn_lobbyists_pressure_reddit_to_shut_down/' ,\n",
      "         'https://www.reddit.com/r/unpopularopinion/comments/l6okyk/i_dont_want_to_be_in_a_relationship_with_someone/' ,\n",
      "         'https://www.reddit.com/r/AskMen/comments/wona9w/men_whats_your_honest_opinion_on_pornography/' ,\n",
      "         'https://www.reddit.com/r/TwoXChromosomes/comments/ua4hdy/teen_should_be_banned_as_a_title_or_tag_for_porn/' ,\n",
      "         'https://www.reddit.com/r/unpopularopinion/comments/9iih3b/porn_has_ruined_an_entire_generations_sexuality/' ,\n",
      "         'https://www.reddit.com/r/SubredditDrama/comments/og8blw/runpopularopinion_turns_into_a_chaotic_warzone/' ,\n",
      "         'https://www.reddit.com/r/unpopularopinion/comments/ofj35h/legal_age_for_porn_stars_should_be_21_not_18/?utm_source=share&utm_medium=web2x&context=3' ,\n",
      "         'https://www.reddit.com/r/sex/comments/3y1sb2/discussion_a_warning_if_you_want_to_get_into_porn/?xpromo_edp=enabled' ,\n",
      "         'https://www.reddit.com/r/sex/comments/qwy190/im_sick_of_having_incest_porn_shoved_in_my_face/?xpromo_edp=enabled' ,\n",
      "         'https://www.reddit.com/r/askgaybros/comments/189xoag/what_are_your_honest_thoughts_on_porn_industry/' ,\n",
      "         'https://www.reddit.com/r/sex/comments/nb9bsc/at_25_im_just_realising_the_influence_porn_has_on/?xpromo_edp=enabled' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/2kzo9k/what_is_a_lie_from_porn_that_you_fell_for/' ,\n",
      "         'https://www.reddit.com/r/philosophy/comments/it083/noam_chomsky_discusses_his_views_on_pornography/' ,\n",
      "         'https://www.reddit.com/r/Equality/comments/81l43/ask_equality_what_is_your_opinion_on_pornography/' ,\n",
      "         'https://www.reddit.com/r/women/comments/cezwpk/women_of_reddit_whats_your_opinion_on_porn/' ,\n",
      "         'https://www.reddit.com/r/philosophy/comments/171xtq/is_pornography_unethical/',\n",
      "         'https://www.reddit.com/r/TwoXChromosomes/comments/xml8as/the_ethics_of_men_watching_porn_wouldnt_bother_me/' ,\n",
      "         'https://www.reddit.com/r/MensLib/comments/jii7wq/pay_for_your_porn/',\n",
      "         'https://www.reddit.com/r/sex/comments/1b2x8r2/is_there_such_thing_as_ethical_porn/',\n",
      "         'https://www.reddit.com/r/changemyview/comments/s7r2vr/cmv_hentai_is_ethical_porn/',\n",
      "         'https://www.reddit.com/r/sex/comments/5b45tk/porn_how_can_i_tell_if_a_porn_studio_is_ethically/',\n",
      "         'https://www.reddit.com/r/DebateReligion/comments/53gxi5/is_porn_ethical/' ,\n",
      "         'https://www.reddit.com/r/Feminism/comments/h7fh4t/how_do_you_feel_about_porn_ethically_speaking/',\n",
      "         'https://www.reddit.com/r/ukpolitics/comments/bf0le1/age_verification_wont_block_porn_but_it_will/' ,\n",
      "         'https://www.reddit.com/r/antipornography/comments/10fe92e/ethical_porn/',\n",
      "         'https://www.reddit.com/r/antipornography/comments/see151/whats_your_opinion_on_ethical_porn/',\n",
      "         'https://www.reddit.com/r/Advice/comments/i5ifvf/how_can_i_watch_porn_ethically/',\n",
      "         'https://www.reddit.com/r/changemyview/comments/185skh3/cmv_i_think_its_insecure_for_people_to_try_to/' ,\n",
      "         'https://www.reddit.com/r/askphilosophy/comments/dxhlua/porn_and_ethics/' ]\n",
      "dfs = []\n",
      "for link in links:\n",
      "    df = submission(link)\n",
      "    dfs.append(df)\n",
      "\n",
      "# Concatenate all dataframes into a single dataframe\n",
      "final_df = pd.concat(dfs, ignore_index=True)\n",
      "dfs = []\n",
      "for link in links:\n",
      "    df = submission(link)\n",
      "    dfs.append(df)\n",
      "    \n",
      "    # Introduce a sleep interval to adhere to the rate limit\n",
      "    time.sleep(1)  # Sleep for 1 second between requests\n",
      "\n",
      "# Concatenate all dataframes into a single dataframe\n",
      "final_df = pd.concat(dfs, ignore_index=True)\n",
      "import time\n",
      "dfs = []\n",
      "for link in links:\n",
      "    df = submission(link)\n",
      "    dfs.append(df)\n",
      "    \n",
      "    # Introduce a sleep interval to adhere to the rate limit\n",
      "    time.sleep(1)  # Sleep for 1 second between requests\n",
      "\n",
      "# Concatenate all dataframes into a single dataframe\n",
      "final_df = pd.concat(dfs, ignore_index=True)\n",
      "import time\n",
      "dfs = []\n",
      "for link in links:\n",
      "    while True:\n",
      "        try:\n",
      "            df = submission(link)\n",
      "            dfs.append(df)\n",
      "            break  # Break the loop if the request is successful\n",
      "        except praw.exceptions.RedditAPIException as e:\n",
      "            if e.error_type == 'RATELIMIT':\n",
      "                # If the error is due to rate limiting, sleep for a while and retry\n",
      "                time.sleep(15)  # Sleep for 15 seconds before retrying\n",
      "            else:\n",
      "                # If it's another type of error, raise it again\n",
      "                raise e\n",
      "\n",
      "# Concatenate all dataframes into a single dataframe\n",
      "final_df = pd.concat(dfs, ignore_index=True)\n",
      "final_df\n",
      "links = ['https://www.reddit.com/r/changemyview/comments/1b2cwhj/cmv_porn_should_not_be_so_normalised/', \n",
      "         'https://www.reddit.com/r/TwoXChromosomes/comments/1b4lyze/these_anti_porn_posts_are_becoming_very_moms_for/' ,\n",
      "         'https://www.reddit.com/r/science/comments/o58b2r/people_who_support_a_ban_on_pornography_tend_to/' , \n",
      "         'https://www.reddit.com/r/Marriage/comments/13jbcdw/this_subreddits_opinions_on_porn_doesnt_matter/',\n",
      "         'https://www.reddit.com/r/dating/comments/rjxcp7/when_youre_in_a_committed_relationship_what_is/' , \n",
      "         'https://www.reddit.com/r/TrueUnpopularOpinion/comments/16htdo9/pornography_is_bad_for_you/' ,\n",
      "         'https://www.reddit.com/r/datingoverthirty/comments/14fh4vl/thoughts_on_porn/' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/18fyqze/what_is_the_worst_porn_you_have_ever_seen/' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/134qwa/have_you_seen_this_ted_talk_about_internet_porn_i/' , \n",
      "         'https://www.reddit.com/r/AskReddit/comments/dl8pgo/people_who_pay_for_porn_why_do_pay_for_porn_what/' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/et5yc/honestly_who_doesnt_watch_porn/' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/1efk7s/what_aspects_about_sex_has_porn_totally_ruined/' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/vaasm/women_of_reddit_how_do_you_feel_about_your_man/' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/9lwt8/do_you_think_porn_harms_your_ability_to_be/' ,\n",
      "         'https://www.reddit.com/r/technology/comments/pba73k/onlyfans_drops_planned_porn_ban_will_continue_to/' ,\n",
      "         'https://www.reddit.com/r/TheGirlSurvivalGuide/comments/gl8ifn/im_really_not_cool_with_porn_anymore_and_i_feel/' ,\n",
      "         'https://www.reddit.com/r/unpopularopinion/comments/cdtjun/porn_is_the_biggest_cancer_to_society_today/' ,\n",
      "         'https://www.reddit.com/r/nottheonion/comments/4kouvz/utah_lawmaker_wants_porn_filtered_from_internet/' ,\n",
      "         'https://www.reddit.com/r/theworldnews/comments/1368ofe/antiporn_lobbyists_pressure_reddit_to_shut_down/' ,\n",
      "         'https://www.reddit.com/r/unpopularopinion/comments/l6okyk/i_dont_want_to_be_in_a_relationship_with_someone/' ,\n",
      "         'https://www.reddit.com/r/AskMen/comments/wona9w/men_whats_your_honest_opinion_on_pornography/' ,\n",
      "         'https://www.reddit.com/r/TwoXChromosomes/comments/ua4hdy/teen_should_be_banned_as_a_title_or_tag_for_porn/' ,\n",
      "         'https://www.reddit.com/r/unpopularopinion/comments/9iih3b/porn_has_ruined_an_entire_generations_sexuality/' ,\n",
      "         'https://www.reddit.com/r/SubredditDrama/comments/og8blw/runpopularopinion_turns_into_a_chaotic_warzone/' ,\n",
      "         'https://www.reddit.com/r/unpopularopinion/comments/ofj35h/legal_age_for_porn_stars_should_be_21_not_18/?utm_source=share&utm_medium=web2x&context=3' ,\n",
      "         'https://www.reddit.com/r/sex/comments/3y1sb2/discussion_a_warning_if_you_want_to_get_into_porn/?xpromo_edp=enabled' ,\n",
      "         'https://www.reddit.com/r/sex/comments/qwy190/im_sick_of_having_incest_porn_shoved_in_my_face/?xpromo_edp=enabled' ,\n",
      "         'https://www.reddit.com/r/askgaybros/comments/189xoag/what_are_your_honest_thoughts_on_porn_industry/' ,\n",
      "         'https://www.reddit.com/r/sex/comments/nb9bsc/at_25_im_just_realising_the_influence_porn_has_on/?xpromo_edp=enabled' ,\n",
      "         'https://www.reddit.com/r/AskReddit/comments/2kzo9k/what_is_a_lie_from_porn_that_you_fell_for/' ,\n",
      "         'https://www.reddit.com/r/philosophy/comments/it083/noam_chomsky_discusses_his_views_on_pornography/' ,\n",
      "         'https://www.reddit.com/r/Equality/comments/81l43/ask_equality_what_is_your_opinion_on_pornography/' ,\n",
      "         'https://www.reddit.com/r/women/comments/cezwpk/women_of_reddit_whats_your_opinion_on_porn/' ,\n",
      "         'https://www.reddit.com/r/philosophy/comments/171xtq/is_pornography_unethical/',\n",
      "         'https://www.reddit.com/r/TwoXChromosomes/comments/xml8as/the_ethics_of_men_watching_porn_wouldnt_bother_me/' ,\n",
      "         'https://www.reddit.com/r/MensLib/comments/jii7wq/pay_for_your_porn/',\n",
      "         'https://www.reddit.com/r/sex/comments/1b2x8r2/is_there_such_thing_as_ethical_porn/',\n",
      "         'https://www.reddit.com/r/changemyview/comments/s7r2vr/cmv_hentai_is_ethical_porn/',\n",
      "         'https://www.reddit.com/r/sex/comments/5b45tk/porn_how_can_i_tell_if_a_porn_studio_is_ethically/',\n",
      "         'https://www.reddit.com/r/DebateReligion/comments/53gxi5/is_porn_ethical/' ,\n",
      "         'https://www.reddit.com/r/Feminism/comments/h7fh4t/how_do_you_feel_about_porn_ethically_speaking/',\n",
      "         'https://www.reddit.com/r/ukpolitics/comments/bf0le1/age_verification_wont_block_porn_but_it_will/' ,\n",
      "         'https://www.reddit.com/r/antipornography/comments/10fe92e/ethical_porn/',\n",
      "         'https://www.reddit.com/r/antipornography/comments/see151/whats_your_opinion_on_ethical_porn/',\n",
      "         'https://www.reddit.com/r/Advice/comments/i5ifvf/how_can_i_watch_porn_ethically/',\n",
      "         'https://www.reddit.com/r/changemyview/comments/185skh3/cmv_i_think_its_insecure_for_people_to_try_to/' ,\n",
      "         'https://www.reddit.com/r/askphilosophy/comments/dxhlua/porn_and_ethics/' ]\n",
      "import time\n",
      "dfs = []\n",
      "for link in links:\n",
      "    while True:\n",
      "        try:\n",
      "            df = submission(link)\n",
      "            dfs.append(df)\n",
      "            break  # Break the loop if the request is successful\n",
      "        except praw.exceptions.RedditAPIException as e:\n",
      "            if e.error_type == 'RATELIMIT':\n",
      "                # If the error is due to rate limiting, sleep for a while and retry\n",
      "                time.sleep(15)  # Sleep for 15 seconds before retrying\n",
      "            else:\n",
      "                # If it's another type of error, raise it again\n",
      "                raise e\n",
      "\n",
      "# Concatenate all dataframes into a single dataframe\n",
      "final_df = pd.concat(dfs, ignore_index=True)\n",
      "import time\n",
      "dfs = []\n",
      "for link in links:\n",
      "    while True:\n",
      "        try:\n",
      "            df = submission(link)\n",
      "            dfs.append(df)\n",
      "            break  # Break the loop if the request is successful\n",
      "        except praw.exceptions.RedditAPIException as e:\n",
      "            if e.error_type == 'RATELIMIT':\n",
      "                # If the error is due to rate limiting, sleep for a while and retry\n",
      "                time.sleep(15)  # Sleep for 15 seconds before retrying\n",
      "            else:\n",
      "                # If it's another type of error, raise it again\n",
      "                raise e\n",
      "\n",
      "# Concatenate all dataframes into a single dataframe\n",
      "final_df = pd.concat(dfs, ignore_index=True)\n",
      "import time\n",
      "dfs = []\n",
      "for link in links:\n",
      "    while True:\n",
      "        try:\n",
      "            df = submission(link)\n",
      "            dfs.append(df)\n",
      "            break  # Break the loop if the request is successful\n",
      "        except praw.exceptions.RedditAPIException as e:\n",
      "            if e.error_type == 'RATELIMIT':\n",
      "                # If the error is due to rate limiting, sleep for a while and retry\n",
      "                time.sleep(30)  # Sleep for 30 seconds before retrying\n",
      "            else:\n",
      "                # If it's another type of error, raise it again\n",
      "                raise e\n",
      "\n",
      "# Concatenate all dataframes into a single dataframe\n",
      "final_df = pd.concat(dfs, ignore_index=True)\n",
      "final_df\n",
      "final_df = df[df.text != '[removed]']\n",
      "final_df = df[df.text != '[removed]']\n",
      "final_df\n",
      "final_df[100:]\n",
      "final_df.top()\n",
      "final_df.head(50)\n",
      "import time\n",
      "dfs = []\n",
      "for link in links:\n",
      "    while True:\n",
      "        try:\n",
      "            df = submission(link)\n",
      "            dfs.append(df)\n",
      "            break  # Break the loop if the request is successful\n",
      "        except praw.exceptions.RedditAPIException as e:\n",
      "            if e.error_type == 'RATELIMIT':\n",
      "                # If the error is due to rate limiting, sleep for a while and retry\n",
      "                time.sleep(30)  # Sleep for 30 seconds before retrying\n",
      "            else:\n",
      "                # If it's another type of error, raise it again\n",
      "                raise e\n",
      "\n",
      "# Concatenate all dataframes into a single dataframe\n",
      "final_df = pd.concat(dfs, ignore_index=True)\n",
      "import time\n",
      "dfs = []\n",
      "for link in links:\n",
      "    while True:\n",
      "        try:\n",
      "            df = submission(link)\n",
      "            dfs.append(df)\n",
      "            break  # Break the loop if the request is successful\n",
      "        except praw.exceptions.RedditAPIException as e:\n",
      "            if e.error_type == 'RATELIMIT':\n",
      "                # If the error is due to rate limiting, sleep for a while and retry\n",
      "                time.sleep(60)  # Sleep for 30 seconds before retrying\n",
      "            else:\n",
      "                # If it's another type of error, raise it again\n",
      "                raise e\n",
      "\n",
      "# Concatenate all dataframes into a single dataframe\n",
      "final_df = pd.concat(dfs, ignore_index=True)\n",
      "final_df.head(50)\n",
      "cleaner_final_df = final_df[final_df.text != '[removed]']\n",
      "cleaner_final_df\n",
      "final_df\n",
      "def lemma(text) :\n",
      "    tokens = word_tokenize(text)\n",
      "    lemmas = [lemmatizer.lemmatize(i.lower()) for i in tokens]\n",
      "    return lemmas\n",
      "lemmas = [lemma(i) for i in cleaner_final_df['text']]\n",
      "#creating a new list called lemmas, calling our lemma function, operating it on i where i is every comment in our data set\n",
      "import nltk\n",
      "nltk.download('punkt')\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "lemmatizer = WordNetLemmatizer()\n",
      "from nltk import stem\n",
      "stemmer = stem.PorterStemmer()\n",
      "from nltk import word_tokenize\n",
      "nltk.download('stopwords')\n",
      "from nltk.corpus import stopwords\n",
      "stops = set(stopwords.words('english'))\n",
      "import string\n",
      "punct = list(string.punctuation)\n",
      "from collections import Counter\n",
      "import requests\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "sns.set()\n",
      "import matplotlib.pyplot as plt\n",
      "!pip install PRAW\n",
      "import numpy as np\n",
      "import praw\n",
      "import datetime\n",
      "\n",
      "reddit = praw.Reddit(user_agent='VAD',\n",
      "                     client_id='ZjY6Q02zjaGNUmfk5b282Q', client_secret=\"sgdNZo6bRPSeCaHAJACK5mNIUxCTgA\",\n",
      "                     username='liflafleof', password='surrenderx3')\n",
      "#nltk.download('wordnet')\n",
      "def lemma(text) :\n",
      "    tokens = word_tokenize(text)\n",
      "    lemmas = [lemmatizer.lemmatize(i.lower()) for i in tokens]\n",
      "    return lemmas\n",
      "lemmas = [lemma(i) for i in cleaner_final_df['text']]\n",
      "#creating a new list called lemmas, calling our lemma function, operating it on i where i is every comment in our data set\n",
      "nltk.download('wordnet')\n",
      "def lemma(text) :\n",
      "    tokens = word_tokenize(text)\n",
      "    lemmas = [lemmatizer.lemmatize(i.lower()) for i in tokens]\n",
      "    return lemmas\n",
      "lemmas = [lemma(i) for i in cleaner_final_df['text']]\n",
      "#creating a new list called lemmas, calling our lemma function, operating it on i where i is every comment in our data set\n",
      "lemmas.head(50)\n",
      "lemmas[50:]\n",
      "lemmas\n",
      "lemmas[1]\n",
      "nltk.download('wordnet')\n",
      "def lemma(text) :\n",
      "    tokens = word_tokenize(text)\n",
      "    lemmas = [lemmatizer.lemmatize(i.lower()) for i in tokens]\n",
      "    return lemmas\n",
      "lemmas = [i for i in lemmas if i not in stops and i not in punct]\n",
      "r_lemmas = [lemma(i) for i in cleaner_final_df['text']]\n",
      "#creating a new list called lemmas, calling our lemma function, operating it on i where i is every comment in our data set\n",
      "lemmas = [i for i in lemmas if i not in stops and i not in punct]\n",
      "r_lemmas = [lemma(i) for i in cleaner_final_df['text']]\n",
      "#creating a new list called lemmas, calling our lemma function, operating it on i where i is every comment in our data set\n",
      "r_lemmas\n",
      "cleaner_lemmas = [i for i in lemmas if i not in stops and i not in punct]\n",
      "lemmas = [lemma(i) for i in cleaner_final_df['text']if i not in stops and i not in punct]\n",
      "#creating a new list called lemmas, calling our lemma function, operating it on i where i is every comment in our data set\n",
      "lemmas\n",
      "nltk.download('wordnet')\n",
      "def lemma(text) :\n",
      "    tokens = word_tokenize(text)\n",
      "    tokens = [token for token in tokens if token not in string.punctuation]\n",
      "    stop_words = set(stopwords.words('english'))\n",
      "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
      "    lemmas = [lemmatizer.lemmatize(i.lower()) for i in tokens]\n",
      "    return lemmas\n",
      "lemmas = [lemma(i) for i in cleaner_final_df['text']]\n",
      "#creating a new list called lemmas, calling our lemma function, operating it on i where i is every comment in our data set\n",
      "lemmas\n",
      "nltk.download('wordnet')\n",
      "def lemma(text) :\n",
      "    tokens = word_tokenize(text)\n",
      "    tokens = [token for token in tokens if token not in string.punctuation]\n",
      "    #stop_words = set(stopwords.words('english'))\n",
      "    #tokens = [token for token in tokens if token.lower() not in stop_words]\n",
      "    lemmas = [lemmatizer.lemmatize(i.lower()) for i in tokens]\n",
      "    return lemmas\n",
      "lemmas = [lemma(i) for i in cleaner_final_df['text']]\n",
      "#creating a new list called lemmas, calling our lemma function, operating it on i where i is every comment in our data set\n",
      "lemmas\n",
      "cleaner_final_df['lemmas'] = lemmas\n",
      "cleaner_final_df = cleaner_final_df.assign(cleaned_lemmas=cleaned_lemmas)\n",
      "cleaner_final_df = cleaner_final_df.assign(lemmas=lemmas)\n",
      "cleaner_final_df\n",
      "nltk.download('wordnet')\n",
      "def lemma(text) :\n",
      "    tokens = word_tokenize(text)\n",
      "    tokens = [token for token in tokens if token not in string.punctuation]\n",
      "    stop_words = set(stopwords.words('english'))\n",
      "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
      "    lemmas = [lemmatizer.lemmatize(i.lower()) for i in tokens]\n",
      "    return lemmas\n",
      "lemmas = [lemma(i) for i in cleaner_final_df['text']]\n",
      "#creating a new list called lemmas, calling our lemma function, operating it on i where i is every comment in our data set\n",
      "lemmas\n",
      "cleaner_final_df = cleaner_final_df.assign(lemmas=lemmas)\n",
      "cleaner_final_df\n",
      "cleaner_final_df.head(100)\n",
      "cleaner_final_df\n",
      "%history\n"
     ]
    }
   ],
   "source": [
    "#  %history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59c7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
